# -*- coding: utf-8 -*-
"""AI Final Project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WZZbe_1azSjfGo1lLvIMToWT4XscMvVJ

Data Preparation and Preprocessing
"""

import pandas as pd
import numpy as np

# Generate synthetic data
np.random.seed(42)

# Number of samples
n_samples = 1000

data = {
    'city': np.random.choice(['CityA', 'CityB', 'CityC', 'CityD'], size=n_samples),
    'country': np.random.choice(['CountryX', 'CountryY', 'CountryZ'], size=n_samples),
    'x1': np.random.uniform(1000, 5000, n_samples),  # Example: income
    'x2': np.random.uniform(500, 1500, n_samples),   # Example: housing costs
    'x3': np.random.uniform(100, 500, n_samples),   # Example: transportation
    # ...
    # Add more features up to x55
    'x55': np.random.uniform(100, 1000, n_samples), # Example: utility costs
    'data_quality': np.random.choice([0, 1], size=n_samples, p=[0.4, 0.6])  # Binary target
}

for i in range(1, 56):
    data[f'x{i}'] = np.random.uniform(100, 1000, n_samples)


# Create DataFrame
df = pd.DataFrame(data)

# Save to CSV
df.to_csv('data.csv', index=False)
print("Mock dataset created and saved as 'data.csv'.")

import pandas as pd
from sklearn.impute import SimpleImputer

try:
    # Try to load 'data.csv'
    data = pd.read_csv('data.csv')
except FileNotFoundError:
    # If 'data.csv' is not found, ask for a new file path
    file_path = input("File 'data.csv' not found. Please enter the correct path: ")
    data = pd.read_csv(file_path)  # Load data from the new path

# Check for missing values
print(data.isnull().sum())

# Impute missing numerical data with mean
num_columns = data.select_dtypes(include=['float64', 'int64']).columns
imputer_num = SimpleImputer(strategy='mean')
data[num_columns] = imputer_num.fit_transform(data[num_columns])

# Impute missing categorical data with mode
cat_columns = data.select_dtypes(include=['object']).columns
imputer_cat = SimpleImputer(strategy='most_frequent')
data[cat_columns] = imputer_cat.fit_transform(data[cat_columns])

print("Missing data handled.")

# One-hot encoding for categorical columns
data = pd.get_dummies(data, columns=['city', 'country'], drop_first=True)
print("Categorical columns encoded.")

from sklearn.preprocessing import StandardScaler

# Extract the cost-related columns (x1 through x55)
cost_columns = [f'x{i}' for i in range(1, 56)]

# Apply StandardScaler to these columns
scaler = StandardScaler()
data[cost_columns] = scaler.fit_transform(data[cost_columns])

print("Feature scaling applied.")

"""Model Training and Hyperparameter Tuning"""

from sklearn.model_selection import train_test_split

# Define target variable (data_quality) and features (all other columns)
X = data.drop('data_quality', axis=1)
y = data['data_quality']

# Split the data into 80% training and 20% testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Data split into train and test sets.")

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV

# Define the model
rf = RandomForestClassifier(random_state=42)

# Set up hyperparameter grid
param_grid = {
    'n_estimators': [100, 200, 500],
    'max_depth': [10, 20, 30, None]
}

# Apply GridSearchCV to tune the hyperparameters
grid_search = GridSearchCV(rf, param_grid, cv=5, n_jobs=-1, scoring='accuracy')
grid_search.fit(X_train, y_train)

# Best model found by GridSearchCV
best_rf = grid_search.best_estimator_
print(f"Best parameters: {grid_search.best_params_}")

"""Model Evaluation

"""

from sklearn.metrics import classification_report, accuracy_score

# Predict on the test set
y_pred = best_rf.predict(X_test)

# Print classification report
print("Classification Report:")
print(classification_report(y_test, y_pred))

# Print accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.4f}")

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

# Confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Plot confusion matrix
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['0', '1'], yticklabels=['0', '1'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

from sklearn.metrics import roc_curve, auc

# Get false positive rate, true positive rate, and thresholds
fpr, tpr, thresholds = roc_curve(y_test, best_rf.predict_proba(X_test)[:,1])

# Calculate AUC score
roc_auc = auc(fpr, tpr)
print(f"AUC Score: {roc_auc:.4f}")

# Plot ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', label=f'AUC = {roc_auc:.2f}')
plt.plot([0, 1], [0, 1], color='red', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc='lower right')
plt.show()

"""Feature Importance Plot"""

# Get feature importances
importances = best_rf.feature_importances_

# Sort the features by importance
indices = importances.argsort()

# Plot feature importance
plt.figure(figsize=(10, 8))
plt.barh(range(len(indices)), importances[indices], align='center')
plt.yticks(range(len(indices)), [X.columns[i] for i in indices])
plt.xlabel('Feature Importance')
plt.title('Feature Importance Plot')
plt.show()

