# -*- coding: utf-8 -*-
"""KevinAguilarUndergradProject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11iexbxXDi4vwzCRBO9XsDUVqFeG6nSYk

# Preprocessing
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import confusion_matrix,accuracy_score,roc_curve,classification_report,auc,roc_auc_score
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
import seaborn as sns
# %matplotlib inline
import matplotlib.pyplot as plt

url = 'https://raw.githubusercontent.com/Aatif123-hub/undergrad-projects/refs/heads/main/Kevin%20Galvan/loan_approval_dataset.csv'
df = pd.read_csv(url)
df

"""Missing Data Handling

"""

df[' residential_assets_value'] = df[' residential_assets_value'].replace(0, np.nan)
df[' commercial_assets_value'] = df[' commercial_assets_value'].replace(0, np.nan)
df[' luxury_assets_value'] = df[' luxury_assets_value'].replace(0, np.nan)
df[' bank_asset_value'] = df[' bank_asset_value'].replace(0, np.nan)

df.isnull().sum()

median_of_residential_assets = df[' residential_assets_value'].median()
median_of_commercial_assets = df[' commercial_assets_value'].median()
median_of_bank_assets = df[' bank_asset_value'].median()
df[' residential_assets_value'] = df[' residential_assets_value'].fillna(median_of_residential_assets)
df[' commercial_assets_value'] = df[' commercial_assets_value'].fillna(median_of_commercial_assets)
df[' bank_asset_value'] = df[' bank_asset_value'].fillna(median_of_bank_assets)

df.isnull().sum()

"""Categorical Encoding"""

df.replace({
    " education": {' Not Graduate': 0, ' Graduate': 1},
    " self_employed": {' No': 0, ' Yes': 1},
    " loan_status": {' Rejected': 0, ' Approved': 1}
}, inplace=True)

df

"""Drop uneccesary values

"""

cols = ['loan_id']
df = df.drop(columns = cols, axis=1)
df.head()

"""Independent Values(X), Dependent Value(Y), Split into Train and Test sets"""

Y = df[" loan_status"]
  X = df.drop([' loan_status'], axis=1)
  X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)

"""Feature Scaling"""

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

X_train

"""Model Training"""

model = LogisticRegression()
model.fit(X_train, Y_train)
Y_prediction = model.predict(X_test)
accuracy = accuracy_score(Y_test, Y_prediction)

"""Evaluation Metrics"""

print("Accuracy: %.2f%%" % (accuracy * 100.0))

report = classification_report(Y_test, Y_prediction)
print(report)

"""Visualizations

"""

c_matrix = confusion_matrix(Y_test, Y_prediction)
sns.heatmap(c_matrix, annot=True, fmt='d')
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

Y_probability = model.predict_proba(X_test)[:, 1]
fpr, tpr, thresholds = roc_curve(Y_test, Y_probability)
roc_auc = auc(fpr, tpr)
plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % roc_auc)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.show()

auc_score = roc_auc_score(Y_test, Y_probability)
print("AUC Score:", auc_score)